{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "715c591d",
   "metadata": {},
   "source": [
    "## Detect Toxic Comments or Statements Using Recurrent_Neural_Network (RNN)\n",
    "### Deep learning AI Algorithm used by Tiktok and other Apps to filter obscene statements or comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da44a215",
   "metadata": {},
   "source": [
    "### Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcc1e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout,Embedding\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "# tf.data.Dataset.list_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df=pd.read_csv(os.path.join('data','train.csv'))\n",
    "# view the data\n",
    "df.head(n=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f3cfa9",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9d3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#defining the Independent variables(Features) X from the depenedent varaiable Y\n",
    "X=df['comment_text'].values # the independent variable\n",
    "y=df[df.columns[2:]].values # dependent variables\n",
    "\n",
    "#init maxima words that would be held as vocabs; many words increase model accuracy whilst slowing training process\n",
    "MAX_VOCAB=200000 \n",
    "\n",
    "# init textVectorisation that will be used to map text features into respective integer values\n",
    "vectorizer=TextVectorization(max_tokens=MAX_VOCAB,output_sequence_length=2000,output_mode='int')\n",
    "\n",
    "# make the vactorizer learn words from the X features\n",
    "vectorizer.adapt(X)\n",
    "\n",
    "#make the vectorizer map the X features to an Integer through mapping techniques\n",
    "vectorized_features=vectorizer(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5989039",
   "metadata": {},
   "source": [
    "### Creating the TensorFlow data Pipeline to ease labeling of the data and training procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#init the data variable using the tensorflow data pipeline with X-vectorized and y-target variable\n",
    "dataset=tf.data.Dataset.from_tensor_slices((vectorized_features,y))\n",
    "\n",
    "#cache the data\n",
    "dataset=dataset.cache()\n",
    "\n",
    "#shuffle the data, the bigger the shuffle size so is the model and training process but highly efficient\n",
    "dataset=dataset.shuffle(160000)\n",
    "\n",
    "#allocate batch size, depends don the GPU size of your system mine has no GPU thus 8 or 16 is better\n",
    "dataset=dataset.batch(16)\n",
    "\n",
    "#add prefetch for continous data inflow at constance\n",
    "dataset=dataset.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780e230c",
   "metadata": {},
   "source": [
    "### Batche(s) for X and y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4902f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X contains the features while y the target as labels\n",
    "batch_X, batch_y=dataset.as_numpy_iterator().next()\n",
    "\n",
    "#viewin the batches\n",
    "batch_X.shape\n",
    "\n",
    "#batch_y\n",
    "batch_y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e994db",
   "metadata": {},
   "source": [
    "### Allocating the dataset for Training (70%), Validation(20%) and Testing(10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4fa6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# training data 70%\n",
    "training_data=dataset.take(int(len(dataset)*0.7))\n",
    "\n",
    "# validation data size 20%\n",
    "validation_data=dataset.skip(int(len(dataset)*0.7)).take(int(len(dataset)*0.2+1))\n",
    "\n",
    "# testing data 10%\n",
    "testing_data=dataset.skip(int(len(dataset)*0.9)).take(int(len(dataset)*0.1+1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94ed3af",
   "metadata": {},
   "source": [
    "### Trainin The Model Using The Long Term Short Memory LSTM  of RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b002efc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#init the seq model\n",
    "model=Sequential()\n",
    "#add embedding layer\n",
    "model.add(Embedding(MAX_VOCAB+1,32))\n",
    "\n",
    "#add the Bidirectional and init the LSTM\n",
    "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
    "\n",
    "#making the  recurrent neural network fully connected using Dense\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "\n",
    "#output neurons (6) using sigmoid for 0 or 1 outoput\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "#compile the model\n",
    "model.compile(optimizer='Adam', loss='BinaryCrossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3b8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04785fa8",
   "metadata": {},
   "source": [
    "### Actual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705e244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a callback log directory helps in referencing and tracking of the train ability\n",
    "log_dir='logs'\n",
    "\n",
    "#dir_isntatiation\n",
    "call_backs_dir=tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "#trainining process\n",
    "ai_model_output=model.fit(training_data, epochs=1, callbacks=call_backs_dir, validation_data=validation_data,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b2d03c",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import CategoricalAccuracy, Recall, Precision\n",
    "\n",
    "recall=Recall()\n",
    "categorical=CategoricalAccuracy()\n",
    "precision=Precision()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fc9b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating over the test data in order to extract  x and y \n",
    "for batch in testing_data.as_numpy_iterator():\n",
    "    x_true,y_true=batch\n",
    "    \n",
    "    #make prediction on the x_true values\n",
    "    y_hat=model.predict(x_true)\n",
    "    \n",
    "    #flatten the prediction matrix to a one dimensional arrray\n",
    "    \n",
    "    y_true=y_true.flatten()\n",
    "    y_hat=y_hat.flatten()\n",
    "    \n",
    "    \n",
    "    #update the model evaluation metrics\n",
    "    recall.update_state(y_true,y_hat)\n",
    "    categorical.update_state(y_true,y_hat)\n",
    "    precision.update_state(y_true,y_hat)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4babd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output the performance of the model using the initialised metrics\n",
    "\n",
    "print(f'\\nPrecison:{precision.result().numpy()}\\n\\n Accuracy:{categorical.result().numpy()}\\n\\n Recall:{recall.result().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034c289c",
   "metadata": {},
   "source": [
    "### save the model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f5fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save using the pickle\n",
    "import pickle\n",
    "\n",
    "pickle_file=open(os.path.join('models','RNN_Toxic_Comment_Model_Pickle.pkl'),mode='wb')\n",
    "pickle.dump(model,pickle_file)\n",
    "pickle_file.close()\n",
    "print('model saved as pickel file successfully\\n')\n",
    "\n",
    "\n",
    "#save using the tensorflow \n",
    "\n",
    "model.save(os.path.join('models','RNN_Toxic_Comment_tf_model.h5'))\n",
    "print('model saved as tensorflow model successfully\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9420b76",
   "metadata": {},
   "source": [
    "### Loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c2c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model saved by pickle file \n",
    "pickle_f=open(os.path.join('models','RNN_Toxic_Comment_Model_Pickle.pkl'),mode='rb')\n",
    "pickle_model=pickle.load(pickle_f)\n",
    "pickle_f.close()\n",
    "\n",
    "print('pickle model loaded successfully\\n')\n",
    "\n",
    "\n",
    "#loading the model saved by the tensorflow\n",
    "model_tf=tf.keras.models.load_model(os.path.join('models','RNN_Toxic_Comment_tf_model.h5'))\n",
    "\n",
    "print('tensorflow model loaded successfully')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b17f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text to predict\n",
    "test_comment='you are a very dumb child'\n",
    "\n",
    "#vectorizing the text for model to read it\n",
    "vectorized_test_comment=vectorizer(test_comment)\n",
    "\n",
    "#loading the saved model both for pickle file format .pkl and tensorflow .h5\n",
    "model_pickle_prediction_results=pickle_model.predict(np.expand_dims(vectorized_test_comment,0))\n",
    "model_tf_prediction_results=pickle_model.predict(np.expand_dims(vectorized_test_comment,0))\n",
    "\n",
    "\n",
    "#viewing the results\n",
    "print('\\nmodel pickle predictdion results: {}'.format(model_pickle_prediction_results>0.5))\n",
    "\n",
    "print('\\nmodel tensorflow predictdion results: {}'.format(model_pickle_prediction_results>0.5))\n",
    "\n",
    "df_columns_predictions=df[df.columns[2:]].head(n=1)\n",
    "df_columns_predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
